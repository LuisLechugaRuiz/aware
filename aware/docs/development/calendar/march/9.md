# Night

## Refactor process to split it between ProcessInterface, MainProcess and InternalProcesses.

So far we have two different classes:

OpenAI tools one -> to fill the prompt on preprocess. For this we need to implement a way to get openai from communications.

And our internal tools which add the should_continue and run_remote.

In the context of Communications we are using the should_continue to determine if we should step or not.

Now is more explicit as we have divided the logic of the two types of processes:

### Main

On main we add communication_protocols, should be renamed to AgentProtocols to help user understand the differentiation with internal_process.

We get the tools from communication_protocols and add them along with the selected tools (based on process state) for current Capability.

This way we will send to the model the communication as potential tools.

After that we need to filter if it is "tool" (our internal tool of each capability) or a communication.

For this we override the process_tool_calls and check it first.

The concept of should_continue applies to step the process. The case of sync request requires to stop stepping when we schedule a new one.
Maybe this should be rethinked. What we can do is to modify directly AgentState, avoid stepping in case of WAITING_FOR_RESPONSE... TBD


### Internal Process

Internal process only modifies the step to add the flag "should_continue" to determine if current process should keep running.

This differentiation is neccesary as internal processes are not managed by communications but by a specific workflow (i.e: for thought until it sends final thought)

For this reason we need to have the decorator @stop_process. It should not be used on main but it will be benefitial for internal processes.


### Summary

I also implemented capability which was needed to split the concept of tools - Capability and tool - Specific method

So now we get the tools directly from capability and can execute them locally (or remotely in the future with a single decorator).

Now at process_interface we have the right logic to add extra tools (by adding @tools) in case of new process class at process_interface (I think it should not be needed after "main" and "internal").

So we use the same logic to provide the tools to the model (main adding communication) and we have slightly different logic to execute the tools as we check by each protocol if it has registered the tool.

Maybe we can also generalize this at post-processing, but for now I have them split as we are using different concepts for "should_continue" and "step".

Maybe we can go back to full interface and we only need to fill tool once at main and dummy internal process to make the difference. TBD.

One more detail:
We also add communication_protocols details at prompt as args for prompt of main processes. Not required and should not be part of internal processes.

### Next:

- Adapt the logic to split capabilities and tools [DONE] - TODO: define it by use-case.
- Refactor preprocess to handle both new processes [WIP]
- Move the logic from thought generator and data storage manager to depend only on AgentData instead of topics/events/requests as this are only for inter-agent communication. []
- Connect CommunicationDispatcher to the different protocols. []
- Refactor internal processes with new prompt inspired by our initial version. []
- Adapt configuration of all agents to follow the state machine format (by default with all available!!!) []
- Agent State machine which will help us to have workflows where only some tools are enable! []
